
= Env discover

== Instantiate Workbench

The demo content includes a number of usecases, we'll use the object detection scenario.

- Login into the {openshift_console_url}[OpenShift Console] with username: {user} and password : {password}
- Click on the top right menu with the squares and select **OpenShift AI** to go the the **OpenShift AI Dashboard**

image::rhoai-menu.png[]

- Login with the same credentials as before 

The is the main Console where all DataScience related projects and assets are managed

- In the left menu click on **Data Science Projects** to see all available Data Science Projects
- A project has already been prepared for you to work in 
- Click on the project `{user}-ai`

Our model training will run in a Pipeline, doing all the heavy lifting of training etc. The prepare our project for pipelines we need to create a **Pipeline Server** :

* Click on **Create a pipeline server**

image::pipeline-server.png[]

* Existing data connection : `model-store-pipeline`
* Click *Configure*

As a true DataScientist we want to use JuypterLab to work on our prediction model. Let's create a new JupyterLab Workbench in our project:

* Click on **Create Workbench**
* Enter these fields :
** Name : `fedora-detection`
** Image selection: `Object Detection``
** Cluster storage 
*** Create new persistent storage:
**** Name : `development``
** Data connections
*** Use a data connection
**** Use existing data connection: `model-store`
* Click Create Workbench

Wait until the **Status** of the Workbench is shown as running

* Click on the `fedora-detection` Workbench link to open the JuypterLab Workbench
* Login with you OpenShift credentials

Now we are going to clone some JuypterNotebooks to get started with our ObjectDetection project:

* In the menu on the left click on the Git icon
* Click on **Clone a Repository**
* Enter the Git Url to the notebooks Repo that has been prepared for you `{gitea_console_url}/{user}/object-detection-notebooks.git
- Click on **Clone**
- On the left side click on the Folder icon and navigate to `object-detection-notebooks`` directory

Next we will train a model on the basis of a Yolov4 Image Detection model to detect Fedoras by giving it sample images. The whole training process will run in a Pipeline leveraging scaling OpenShift ressources. Sample images will be downloaded automatically and after the training the model will be exported in onnx format to your S3 store. In the format we can use it to provide an inferencing service to our app.

- Navigate to ´model-training´
- Open `model-training-cpu.pipeline`
- On the top menu on left click on the play icon
- 

reate and run the model training as a pipeline with Elyra and Data Science Pipelines. The training pipeline uses images from the Open Images Dataset V7. (https://storage.googleapis.com/openimages/web/index.html)
We'll use three classes in our training: Ball, Tennis ball and Fedora. Access the image database website, click Explore, search for the classes and have a look at the images. To configure the pipeline, open the file configuration.yaml in the Jupyter Notebook and replace the class names with the classes listed above. Hit Ctrl-s to save.
In the Jupyter Notebook navigate to the os-mlops/notebooks/object-detection_example/model-training folder
Open the appropriate Elyra pipeline, i.e. model-training-gpu.pipeline if you have enabled GPUs in your cluster, else model-training-cpu.pipeline.
Open configuration.yaml
Set 
: names: ['Fedora', 'Ball', 'Tennis ball']
Save the file
In the Pipeline Editor click Run Pipeline to submit the pipeline to the Data Science Pipelines backend.
Track the pipeline progress in the RHODS dashboard: Data Science Pipelines->Runs->Triggered
Once the pipeline run has completed, check for the trained model in the object-detection bucket in Minio using the Object Browser.

== Model Serving
You now have a trained model for object recognition. To use the model we deploy it into RHODS Model Serving:
Access the RHODS dashboard, in Data Science Projects choose object-detection
Under Models and model servers click Deploy model for the appropriate model server, i.e. Triton if you enabled GPUs in your cluster, else OVMS.
In the form enter
Project: object-detection
Model Name: demo-model
Model framework: ONNX
Choose Existing data connection: object-detection
model-latest.onnx as Folder path.

Select Deploy
Wait for the server to start
Copy the Inference endpoint URL
Open the online-scoring notebook.
Paste the inference endpoint URL into the placeholder of the prediction_url variable.
Make sure the class labels are
 ['Fedora', 'Ball', 'Tennis ball']
Run the full notebook (The with the two Play Icons)
You will see the identified cluster


== Model Testing
Open the Notebook object-detection-example/model-training/os-mlops/notebooks/object-detection-example/online-scoring.ipynb
Run the entire Notebook (Double Play Icon)
Upload an Image of your own sample-images
Reference it in image_path = './sample-images/<Your Image>
And run the testing again  

