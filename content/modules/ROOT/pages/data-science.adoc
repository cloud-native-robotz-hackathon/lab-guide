
= Data Science

As Data Scientist our task will be to give our robot understanding of what a red fedora looks like and how to identify one. You will train an existing object dection model (Yolo) on a set of images depicting fedoras. To achieve this we will use **OpenShift AI**, an extension to OpenShift that provides a platform for Data Scientist to work with the tools they are used to.

== Instantiate Workbench

Let's login into **OpenShift AI**

* Login into the {openshift_console_url}[OpenShift Console] with:
** username: {user}
** password : {password}
* Click on the top right menu with the squares and select **OpenShift AI** to access the **OpenShift AI Dashboard**

image::rhoai-menu.png[]

* Click on **Login with OpenShift**
* Login with the same credentials as before

The is the main Console where all DataScience related projects and assets are managed

- In the left menu click on **Data Science Projects** to see all available Data Science Projects
- A project has already been prepared for you to work in
- Click on the project `{user}-ai`

As a true DataScientist we want to use JuypterLab to work on our prediction model. Let's create a new JupyterLab Workbench in our project:

* Click on **Create Workbench**
* Enter these fields :
** Name :
+
[source,bash,role=execute]
----
fedora-detection
----

** Image selection: `Object Detection`
** Cluster storage
*** Create new persistent storage:
**** Name : `fedora-detection`
** Data connections
*** Use a data connection
**** Use existing data connection: `workbench-bucket`
* Click **Create Workbench**

Wait until the **Status** of the Workbench is shown as running

image::workbench-running.png[]

* Click on the **Open** link, next to the `fedora-detection` Workbench to open the JuypterLab Workbench
* Login with you OpenShift credentials and allow selected permissions

In JuypterLab we are going to clone some JuypterNotebooks to get started with our ObjectDetection project:

* In the menu on the left, click on the **Git** icon
* Click on **Clone a Repository**
* Enter the Git Url to the notebooks Repo that has been prepared for you :
+
[source,bash,role=execute,subs="attributes"]
----
{gitea_console_url}/{user}/object-detection-notebooks.git
----

* Click on **Clone**
* On the left side in the menu click on the **Folder** icon and navigate to `object-detection-notebooks` directory

Next we will train a model on the basis of a Yolo4 Image Detection model to identify fedoras by giving it sample images. The whole training process will run in a Pipeline leveraging OpenShift ressource scaling. Sample images will be downloaded automatically and after the training the model will be exported in onnx format to your S3 ODF store. In this format we can deploy it to an inferencing service of **OpenShift AI** and serve it to our application.

* In JupyterLab navigate to the directory ´object-detection-notebooks/model-training´
- Open `model-training-cpu.pipeline`

Have a look at the pipeline steps: We are downloading sample images, preparing the labels and training sets, running the training, converting the model format to onnx and then uploading it to an S3 bucket.

The pipeline can be configured to download and train on image object classes (e.g. Fedoras) from the OpenImages website. To configure these classes open the file `configuration.yaml`. You will see some classes have already been set ('Laptop', 'Computer keyboard', 'Table'). We will change these to detect the objects we are looking for.

* Change the `names` array to look like this

[source,yaml,role=execute,subs="attributes"]
----
names: ['Fedora', 'Ball', 'Tennis ball',]
----

These image classes are mapped to the class numbers 0, 1, 2 accordingly, press Ctrl-s to save your changes.

* Now back in the `model-training-pipeline`, on the top menu on the left click on the play icon
+
image::start-pipeline.png[]

* Keep the default settings and click on **OK**

This will submit the pipeline to OpenShift to run the training

* Switch to the *OpenShift AI* tab in your browser
* Select your Data Science Project {user}-ai
* Select **Pipelines** tab
* Expand the **model-training-cpu** Pipeline
* Click on the three dots at the end of line
* Click on **View runs**
+
image::view-runs.png[]

* Click on **model-training-cpu-xxxxx** at the Run column
+ 
image::view-runs2.png[]

* Click on the currently running pipeline

This will show the running steps of the pipeline

image::running-pipeline.png[]

Now is a good time to grab some coffee.

Once the pipeline has run successfully the final model named `latest-version.onnx` will be saved in your S3 bucket.

== Model Serving
You now have a trained model for object recognition. To use the model we will deploy it into **OpenShift AI** Model Serving, which will make it available via an API.

=== Model Runtime

First we need to configue a model server:

* Click on **DataScience Projects** in the main menu on the left and make sure you have selected your project again
* Select your Data Science Project {user}-ai
* Under the section **Serve models** click on **Add model server**
* Model server name :
+
[source,bash,role=execute,subs="attributes"]
----
ovms
----
* Serving runtime : `OpenVINO Model Server`
* Make deployed models available ... : `Check`
* Require token authentication : `Check`
** Service account name : `default-name`
* Keep the rest of the settings as is
* Click **Add**

image::serving-runtime.png[]

=== Deploy Model

* Click **Go to Models** next to your just created model server
* Click **Deploy model**
* In the form enter
** Model Name:
+
[source,bash,role=execute,subs="attributes"]
----
fedora-detection-service
----
** Model framework (name-version): `onnx-1`
** Existing data connection: `workbench-bucket`
** Path:
+
[source,bash,role=execute,subs="attributes"]
----
models/model-latest.onnx
----
** Click **Deploy**

Wait for the server to start

=== Model Testing

* Copy the inference endpoint URL that is published through an OpenShift Route

image::copy-inference-url.png[]

* Copy the token of the endpoint

image::copy-token.png[]

* Back in your JupyterLab Workbench in the `object-detection-notebooks` directory, open the `online-scoring.ipynb` notebook
* Look for the variables `prediction_url` and `token` and paste the inference endpoint URL and the token into the placeholders

* Run the full notebook (The button with the two play icons in the top menu)
* Confirm to **Restart the Kernel**

You will see any identified classes with bounding boxes and confidence score. Bummer! As the sample image doesn't have any fedoras you will not see any detections yet. Let's give our more model some more interesting pictures.

You can test your model with different images in the `sample-images` folder. But even better you can upload your own images. Take some pictures with your laptop or smartphone of a fedora on the floor and upload them into the `sample_images` folder.  Make sure you adjust the image name in `image_path` variable before running the notebook again. You should see awesome some detections now.

Now it is time to handoff your amazing AI Fedora Detection service to the dev team. Make a note and use the two values `prediction_url` and `token` in your app in the next chapter.
