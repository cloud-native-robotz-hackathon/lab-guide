
= Data Science

== Instantiate Workbench

The demo content includes a number of usecases, we'll use the object detection scenario.

- Login into the {openshift_console_url}[OpenShift Console] with username: {user} and password : {password}
- Click on the top right menu with the squares and select **OpenShift AI** to go the the **OpenShift AI Dashboard**

image::rhoai-menu.png[]

- Login with the same credentials as before

The is the main Console where all DataScience related projects and assets are managed

- In the left menu click on **Data Science Projects** to see all available Data Science Projects
- A project has already been prepared for you to work in
- Click on the project `{user}-ai`

[.lines_space]
[.console-input]
[source,bash,role=execute,subs="attributes"]
----
{user}-ai
----

As a true DataScientist we want to use JuypterLab to work on our prediction model. Let's create a new JupyterLab Workbench in our project:

* Click on **Create Workbench**
* Enter these fields :
** Name : `fedora-detection`
** Image selection: `Object Detection`
** Cluster storage
*** Create new persistent storage:
**** Name : `fedora-detection`
** Data connections
*** Use a data connection
**** Use existing data connection: `workbench-bucket`
* Click Create Workbench

Wait until the **Status** of the Workbench is shown as running

* Click on the `fedora-detection` Workbench link to open the JuypterLab Workbench
* Login with you OpenShift credentials

Now we are going to clone some JuypterNotebooks to get started with our ObjectDetection project:

* In the menu on the left click on the Git icon
* Click on **Clone a Repository**
* Enter the Git Url to the notebooks Repo that has been prepared for you `{gitea_console_url}/{user}/object-detection-notebooks.git``
- Click on **Clone**
- On the left side click on the Folder icon and navigate to `object-detection-notebooks`` directory

Next we will train a model on the basis of a Yolo4 Image Detection model to detect Fedoras by giving it sample images. The whole training process will run in a Pipeline leveraging scaling OpenShift ressources. Sample images will be downloaded automatically and after the training the model will be exported in onnx format to your S3 store. In the format we can use it to provide an inferencing service to our app.

- Navigate to ´model-training´
- Open `model-training-cpu.pipeline`

Have a look at the pipeline steps: We are downloading sample images, preparing the labels and training sets, running the training, converting the model format to onnx and then uploading it to an S3 bucket

The pipeline can be configured to download and train on image obeject classes (e.g. Fedoras). To configure these classes open the file `configuration.yaml` You will see some classes have already been set ('Laptop', 'Computer keyboard', 'Table'). We will change these to detect some objects that we might have

* Change the `names` array to look like this
[,yaml]
----
names: ['Fedora', 'Ball', 'Tennis ball',]
----
These Image classes are mapped to the class numbers 0, 1, 2 accordingly

* Now back in the pipelines, on the top menu on left click on the play icon
* Keep the default settings and click on **OK**

This will submit the pipeline to OpenShift to run the training

* Switch to the RHOAI Tab in your browser
* Expand the **pipelines** section of your DataScience Project and you will see the Pipeline instance
* Click on the pipeline name and the pipeline view will open showing you the how the steps are excecuting

Now is a good time to grab some coffee.

Once the pipeline has run successfully the final model named `latest-version.onnx` will be in your S3 bucket.

== Model Serving
You now have a trained model for object recognition. To use the model we deploy it into RHOAI Model Serving:

=== Model Runtime

First we need to configue a model server:
* Access the Data Science dashboard and make sure you have selected your project again
*  Under **Models and model servers** click on **Add model server**
* Model server name : `ovms`
* Serving runtime : `OpenVINO Model Server`
* Make deployed models available ... : `Check``
* Require token authentication : `Check``
** Service account name : `default-name`
* Keep the rest of the settings as is
* Click **Add**

image::serving-runtime.png[]

=== Deploy Model

* click **Deploy model** next to your just created model server
* In the form enter
** Model Name: `fedora-detection-service``
** Model framework (name-version): `o nnx-1``
** Existing data connection: `workbench-bucket`
** Path: `models/model-latest.onnx``
** Click **Deploy**

Wait for the server to start

=== Model Testing

* Copy the Inference endpoint URL

image::copy-inference-url.png[]
* Copy the token of the endpoint

image::copy-token.png[]

* Back in your JupyterLab open the `online-scoring.ipynb` notebook
* Look for cell [3] and paste the inference endpoint URL and the token into the placeholders of the `prediction_url` and `token` variables

* Run the full notebook (The button with the two play Icons)

You will see the identified classes with bounding boxes and confidence score

TIP: You can test this with different images in the sample-images folder. You can even upload your own images. Just make sure you adjust the image name in cell [2]

Now it is time to handoff your amazing AI Fedora Detection service to the dev team. Use the two values (prediction_url` and `token`) in your app in the next chapter.



==  Build container image with the model

This is important for the robot deployment later.

- Login into the {openshift_console_url}[OpenShift Console] with username: {user} and password : {password}

- Go to ({openshift_console_url}k8s/ns/{user}-ai/tekton.dev~v1~Pipeline/model-image-build)[Pipelines]
- Select `modile-image-build`
- Start the pipeline