<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Data Science :: Cloud Native Robotz Hackathon</title>
    <link rel="canonical" href="https://cloud-native-robotz-hackathon.github.io/modules/stable/data-science.html">
    <link rel="prev" href="index.html">
    <link rel="next" href="control-robot.html">
    <meta name="generator" content="Antora 3.0.0">
    <link rel="stylesheet" href="../../_/css/site.css">
<link rel="icon" href="../../_/img/favicon.ico" type="image/x-icon">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <img src="../../_/img/robot.png" />
      <h1>&nbsp;&nbsp;Cloud Native Robotz Hackathon</h1>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" target="_blank" href="https://github.com/cloud-native-robotz-hackathon/infrastructure/issues/new">Feedback</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="modules" data-version="stable">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html" class=" query-params-link">Lab guide</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="data-science.html">0. Data Science</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="control-robot.html">1. Control your Robot</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="develop-controlapp.html">2. Develop Control Application</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="improve-app1.html">3. Improve Control App Part 1</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="improve-app2.html">4. Improve Control App Part 2</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="auto-robot.html">5. The Autonomous Robot: Compete!</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="challenge-2.html">6. Final Challenge</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="appendix.html">Appendix</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Lab guide</span>
    <span class="version">stable</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Lab guide</span>
      <ul class="versions">
        <li class="version is-current">
          <a href="index.html">stable</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Lab guide</a></li>
    <li><a href="data-science.html">0. Data Science</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="https://github.com/cloud-native-robotz-hackathon/lab-guide/edit/main/content/modules/ROOT/pages/data-science.adoc">Edit this Page</a></div>
  </div>
  <div class="content">
<article class="doc">
<h1 class="page">Data Science</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>As Data Scientists, we have been given a task to provide a robot the understanding of what a red hat (a fedora) looks like, correctly identify it and act on the object detection. You will be fine tuning an object dection model from the <a href="https://docs.ultralytics.com/models/yolov5/" target="_blank" rel="noopener">YOLO-family</a> (You Only Look Once), on a set of fedora images we prepared for you. To achieve this we will use <strong>OpenShift AI</strong>, an extension to OpenShift that provides a platform for Data Scientists to work with their favourite tools and libraries.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_instantiate_workbench"><a class="anchor" href="#_instantiate_workbench"></a>Instantiate Workbench</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Let&#8217;s login into <strong>OpenShift AI</strong></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Most of the applications you are about to use are enabled for Single Sign-On using <strong>Red Hat build of Keycloak</strong>. So when you first access the OpenShift Console, you&#8217;ll be directed to Keycloak for authentication.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Login into the Keycloak Realm by accessing the <a href="https://console-openshift-console.apps.example.com" target="_blank" rel="noopener">OpenShift Console</a> with:</p>
<div class="ulist">
<ul>
<li>
<p>username:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">team-1</code></pre>
</div>
</div>
</li>
<li>
<p>password :</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">secret-password</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>After you have authenticated you&#8217;ll get to the OpenShift Console.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Click <strong>Skip tour</strong></p>
<div class="imageblock text-left">
<div class="content">
<img src="_images/skip-tour.png" alt="skip tour" width="420">
</div>
</div>
</li>
<li>
<p>Click on the top right menu with the squares and select <strong>OpenShift AI</strong> to access the <strong>OpenShift AI Dashboard</strong></p>
<div class="imageblock text-left">
<div class="content">
<img src="_images/rhoai-menu.png" alt="rhoai menu" width="350">
</div>
</div>
</li>
<li>
<p>Click on <strong>Login with OpenShift</strong></p>
</li>
<li>
<p>Thanks to the SSO magic you don&#8217;t have to authenticate again</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This is the main Console where all Data Science related projects and assets are managed.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>In the left menu click on <strong>Data Science Projects</strong> to see all available Data Science Projects</p>
</li>
<li>
<p>A project has already been prepared for you to work in</p>
</li>
<li>
<p>Click on the project <code>team-1-ai</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>As Data Scientists, we are in need of an interactive developement environment(IDE) to do our programming. One of the most common one (and provided by OpenShift AI) is JupyterLab. Let&#8217;s create a new JupyterLab Workbench in our Data Science project and get started:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Click on <strong>Create Workbench</strong></p>
</li>
<li>
<p>Enter these fields :</p>
<div class="ulist">
<ul>
<li>
<p><strong>Name:</strong></p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">fedora-detection</code></pre>
</div>
</div>
</li>
<li>
<p><strong>Notebook image</strong></p>
<div class="ulist">
<ul>
<li>
<p>Image selection: <code>Object Detection</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Deployment size</strong></p>
<div class="ulist">
<ul>
<li>
<p>Container size: 'Small'</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Cluster storage</strong></p>
<div class="ulist">
<ul>
<li>
<p>Click on <strong>Attach existing storage</strong></p>
<div class="ulist">
<ul>
<li>
<p>Select <code>object-detection-training-pvc</code> connection</p>
</li>
<li>
<p><strong>Standard Path</strong></p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">object-detection-training-pvc</code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/attach-existing-storage.png" alt="attach existing storage">
</div>
</div>
</li>
<li>
<p>Click on <strong>Attach storage</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Connections</strong></p>
<div class="ulist">
<ul>
<li>
<p>Click on <strong>Attach existing connections</strong></p>
<div class="ulist">
<ul>
<li>
<p>Select <code>workbench-bucket</code> connection</p>
<div class="imageblock">
<div class="content">
<img src="_images/attach-existing-connection.png" alt="attach existing connection">
</div>
</div>
</li>
<li>
<p>Click on <strong>Attach</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Click on <strong>Create Workbench</strong></p>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Wait until the <strong>Status</strong> of the Workbench is changed from "Starting" to "Running", this can take 2-3 minutes.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/workbench-running.png" alt="workbench running">
</div>
</div>
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_create_your_model_in_jupyterlab"><a class="anchor" href="#_create_your_model_in_jupyterlab"></a>Create your Model in JupyterLab</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Click on the Open link, next to the Workbench name link to open the JuypterLab Workbench</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The first thing we notice when logging into our workbench is that it&#8217;s quite empty. If this is your first time seeing JupyterLab, take a couple of minutes to look around! But don&#8217;t worry, we are experienced Data Scientists who know the importance of documentation, version handling and reproducability. Therefore, in JuypterLab we are going to clone a complete JuypterNotebook to get started with our object detection project:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>In the menu on the left, click on the <strong>Git</strong> icon</p>
</li>
<li>
<p>Click on <strong>Clone a Repository</strong></p>
</li>
<li>
<p>Enter the Git Url to the notebooks repo that has been prepared for you:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">https://gitea.apps.example.com/team-1/object-detection-notebooks.git</code></pre>
</div>
</div>
</li>
<li>
<p>Click on <strong>Clone</strong></p>
<div class="imageblock">
<div class="content">
<img src="_images/workbench-clone.png" alt="workbench clone" width="420">
</div>
</div>
</li>
<li>
<p>On the left side in the menu click on the <strong>Folder</strong> icon.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Next, we will train our model on the basis of a <a href="https://docs.ultralytics.com/models/yolov5/" target="_blank" rel="noopener">Yolo5</a> Image Detection model to identify fedoras by providing sample images. The whole training process will run in a Pipeline leveraging OpenShift resource scaling.</p>
</div>
<div class="paragraph">
<p>We will provide sample images but you will add some images of your own as well to customize this model yourself.  After the training, the model will be exported in onnx format to your S3 <strong>ODF</strong> (OpenShift Data Foundation) bucket. In this format we can deploy it to an inferencing service on <strong>OpenShift AI</strong> and serve it to our application.</p>
</div>
<div class="sect2">
<h3 id="_the_training_images"><a class="anchor" href="#_the_training_images"></a>The Training Images</h3>
<div class="paragraph">
<p>To stay in the boundaries of the resources available to us, we provide around 100 images of a Red Hat Fedora together with the label metadata to train our base model with.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Labeling in object detection is the annotation of raw image by humans, where bounding boxes are drawn around specific objects and assign a class label (e.g., "car", "person," "tree". Or "fedora"&#8230;&#8203;) to each object. This basically teaches the base model to recognize a new class of objects.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Since we deliberately don&#8217;t have a lot of variations in the images this will lead to a model that will recognize this particular Fedora pretty well, but not one that deviates slightly. This is commonly called "overfitting" and usually avoided, but in our case for demo and fun it&#8217;s fine.</p>
</div>
<div class="paragraph">
<p>If you would like to get a idea what the images look like, in your JupyterLab Notebook navigate to the folder <code>object-detection-training-pvc/custom_training_images/fedora/images/</code> and open some of the images. You&#8217;ll see slight variations of a Red Hat Fedora in front of varying backgrounds.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/training-image.png" alt="training image">
</div>
</div>
<div class="paragraph">
<p>Labeling data in form of a bounding box around the object in question "tells" the model during the training what part of the image is actually the Fedora. This data is kept in  a different folder, if you go to the folder <code>labels</code> you&#8217;ll see text files, each corresponding to one of the images. If you open one of the label files there are coordinates of a rectangle, this describes the bounding box.</p>
</div>
</div>
<div class="sect2">
<h3 id="_image_labeling"><a class="anchor" href="#_image_labeling"></a>Image Labeling</h3>
<div class="paragraph">
<p>Since image preparation and labeling is an important part of working in data science, even if we provide the training image data set we&#8217;d like to provide you with the opportunity to learn how images are labeled. You&#8217;ll basically add some more images to the training data yourself.</p>
</div>
<div class="paragraph">
<p>There are a good number of tools available for this task, we&#8217;ll use a well-known Open Source project called <strong>Label Studio</strong>. Label Studio runs in OpenShift, of course, and was already deployed for you.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Login into the <a href="https://web-team-1-label-studio.apps.example.com" target="_blank" rel="noopener">Label Studio</a> with:</p>
<div class="ulist">
<ul>
<li>
<p>E-Mail Address:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">team-1@example.com</code></pre>
</div>
</div>
</li>
<li>
<p>Password :</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">secret-password</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>This will take you to the Label Studio Welcome page.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/label-studio-welcome.png" alt="label studio welcome">
</div>
</div>
<div class="paragraph">
<p><strong>Configure Label Studio</strong></p>
</div>
<div class="paragraph">
<p>Click <strong>Create Project</strong> to get started:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Project Name:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Fedora</code></pre>
</div>
</div>
</li>
<li>
<p>Click <strong>Save</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Now you have to configure Label Studio for the way you going to label the images. Click <strong>Settings</strong> to the upper right, then:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Choose <strong>Labeling Interface</strong> from the menu to the left</p>
</li>
<li>
<p>Click on <strong>Browse Templates</strong></p>
</li>
<li>
<p>From <strong>Computer Vision</strong> choose <strong>Object Detection with Bounding Boxes</strong></p>
</li>
<li>
<p>Under <strong>add label names</strong> there will be two labels ("Airplane" and "Car") preconfigured, delete them by clicking the red X.</p>
</li>
<li>
<p>In the text box enter our label "Fedora" and click <strong>Add</strong></p>
</li>
<li>
<p>Click <strong>Save</strong></p>
</li>
<li>
<p>Return to the Project overview by clicking <strong>Fedora</strong> in the breadcrumb-style path at the top.</p>
<div class="imageblock">
<div class="content">
<img src="_images/label-studio-settings.png" alt="label studio settings">
</div>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>You&#8217;ll be greeted with <strong>Looks like you have not imported any data yet</strong>&#8230;&#8203; true, we need some images first before we can proceed to labeling them:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Click <strong>Go to import</strong></p>
</li>
<li>
<p>Take some images of the Fedora on the floor with your mobile phone. Make sure they are in jpg-format.</p>
<div class="ulist">
<ul>
<li>
<p>Or use these two images:</p>
<div class="ulist">
<ul>
<li>
<p><a href="_images/fedora-demo-image-1.jpg">fedora-demo-image-1.jpg</a></p>
</li>
<li>
<p><a href="_images/fedora-demo-image-2.jpg">fedora-demo-image-2.jpg</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Make sure the camera is taking pictures in JPG format and not HEIC or any other fancy format&#8230;&#8203; :-)</p>
</li>
<li>
<p>If the file extension is not jpg (but jpeg), rename the extension.</p>
</li>
<li>
<p>Transfer them to your laptop and upload them via <strong>Upload Files</strong>, you can upload multiple images at once.</p>
</li>
<li>
<p>Click <strong>Import</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Your UI should now look like this, obviously with different images&#8230;&#8203; ;-)</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/label-studio-images.png" alt="label studio images">
</div>
</div>
<div class="paragraph">
<p><strong>Label your Images</strong></p>
</div>
<div class="paragraph">
<p>Now it&#8217;s time to actually label the images.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Click the images to start</p>
</li>
<li>
<p>You&#8217;ll get into the labeling interface. To label a class, you have to choose it at the bottom. We only have on class, Fedora, so click to activate it.</p>
</li>
<li>
<p>Now in the image draw a rectangle by holding the left mouse button <strong>as close to the Fedora as close as possible</strong>.</p>
</li>
<li>
<p>Click <strong>Submit</strong></p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/label-studio-labeling.png" alt="label studio labeling">
</div>
</div>
<div class="paragraph">
<p>Congrats, you have just labeled your first image! Now do the same for the rest of your images. When you are done with labeling you can use the images with their labels for training the model. We just have to transfer them to your JupyterLab Notebook to add them to the training images.</p>
</div>
<div class="paragraph">
<p><strong>Transfer Labeled Images</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>On the overview page of your Label Studio project (click on the <strong>Fedora</strong> in the breadcrumbs menu) click <strong>Export</strong></p>
<div class="imageblock">
<div class="content">
<img src="_images/label-studio-export.png" alt="label studio export">
</div>
</div>
</li>
<li>
<p>and as format choose <code>YOLO with Images</code>.</p>
</li>
<li>
<p>Click <strong>Export</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This will download a zip file with the images and label metadata to your laptop. Inspect the content of the file, you&#8217;ll find an <code>images</code> and a <code>labels</code> folder with the same content format you have in the training images provided by us.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Transfering the labeled images via zip file is of course not the way you would do this in the real world, here you would use e.g. an S3 bucket for data transfer.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Now add the images to the training images in the JupyterLab Notebook:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Unpack the zip file</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">.
├── classes.txt
├── images
│   ├── 6778ae02-fedora-demo-image-2.jpg
│   └── ea65fd5b-fedora-demo-image-1.jpg
├── labels
│   ├── 6778ae02-fedora-demo-image-2.txt
│   └── ea65fd5b-fedora-demo-image-1.txt
└── notes.json

3 directories, 6 files</code></pre>
</div>
</div>
</li>
<li>
<p>Go back to your <strong>JupyterLab notebook</strong></p>
</li>
<li>
<p>open the folder <code>object-detection-training-pvc/custom_training_images/fedora/</code></p>
<div class="imageblock">
<div class="content">
<img src="_images/workbench-upload-1.png" alt="workbench upload 1">
</div>
</div>
</li>
<li>
<p>Open the <code>images</code> folder</p>
<div class="ulist">
<ul>
<li>
<p>upload your images using the <strong>Upload Files</strong> button.</p>
</li>
<li>
<p>Select the all images in the <code>images</code> folder of the zip file.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Open the <code>labels</code> folder</p>
<div class="ulist">
<ul>
<li>
<p>upload your label files using the <strong>Upload Files</strong> button.</p>
</li>
<li>
<p>Select the all label files in the <code>labels</code> folder of the zip file.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Now you are ready to train your model!</p>
</div>
</div>
<div class="sect2">
<h3 id="_model_training"><a class="anchor" href="#_model_training"></a>Model Training</h3>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When training the model the confidence score and accuracy will be a limiting factor going forward. In order to stay within hardware restrictions such as no GPUs in the data center and the physical robot, a compromise has been made in terms of the size of the base model as well as training epochs, batch size, number of images to train upon and how much time will be left on the hackathon for other tasks. Of course, these variables may be changed by you attendees, however, the changes such as increased epoch and increased sample count might yield little to no improvement while taking longer time to train.</p>
</div>
<div class="paragraph">
<p>This is a limiting factor edge cases face, finding the balance between accuracy and sizing requirements for the model to run.</p>
</div>
<div class="paragraph">
<p>Therefore, have some realistic expectations on the model and dont get hooked up on fine tuning it.</p>
</div>
<div class="paragraph">
<p>If we accept this, lets go ahead and train the model!</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>In JupyterLab navigate to the directory <code>object-detection-notebooks/model-training</code>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Notice that we now have a couple of python scripts containing code to execute the individual steps of the pipeline, a <code>configuration.yaml</code> file as well as pipeline definition itself. By clicking on the different scripts, you can view and edit them in your IDE. However, we are specifically interested in the pipeline definition, so let&#8217;s open it:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Double click on <code>model-training-cpu.pipeline</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This will show you a view of our Data Science Pipeline. This pipeline runs several steps / Python scripts in sequence to train our model. Again you don&#8217;t have to change anything here but feel free to have a look at the steps by clicking on them.</p>
</div>
<div class="paragraph">
<p>Here is a quick explanation what each step of the Pipeline does:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Step 1 : Prepares the class labels, images and bounding box coordinates as training sets</p>
</li>
<li>
<p>Step 2 : Runs the actual training on a <a href="https://docs.ultralytics.com/models/yolov5/" target="_blank" rel="noopener">Yolo 5</a> Model</p>
</li>
<li>
<p>Step 3 : Converts the model format to onnx</p>
</li>
<li>
<p>Step 4 : Uploads it to an ODF S3 bucket</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Now back in the <code>model-training-cpu.pipeline</code>, on the top menu on the left click on the play icon</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/start-pipeline.png" alt="start pipeline">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Keep the default settings and click on <strong>OK</strong></p>
</li>
<li>
<p>Click on <strong>OK</strong> at the <strong>Job submission to Data Science Pipelines succeeded</strong> dialog</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This will submit the pipeline to OpenShift to run the training</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Switch to the <strong>OpenShift AI</strong> tab in your browser</p>
</li>
<li>
<p>Select your Data Science Project team-1-ai</p>
</li>
<li>
<p>Select <strong>Pipelines</strong> tab</p>
</li>
<li>
<p>Expand the <strong>model-training-cpu</strong> Pipeline by clicking on the <strong>&gt;</strong></p>
</li>
<li>
<p>Click on <strong>View runs</strong></p>
<div class="imageblock">
<div class="content">
<img src="_images/view-runs.png" alt="view runs">
</div>
</div>
</li>
<li>
<p>Click on <strong>model-training-cpu-xxxxx</strong> at the Run column</p>
<div class="imageblock">
<div class="content">
<img src="_images/view-runs2.png" alt="view runs2">
</div>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>This will show the running steps of the pipeline</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/running-pipeline.png" alt="running pipeline">
</div>
</div>
<div class="paragraph">
<p>With the default settings, the Pipeline will run around 15 minutes.  Let&#8217;s use the time to deploy another Workbench that we can use to inspect our S3 bucket and see our model when ready.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deploy_s3_browser"><a class="anchor" href="#_deploy_s3_browser"></a>Deploy S3 Browser</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>In the left menu click on <strong>Data Science Projects</strong> to see all available Data Science Projects</p>
</li>
<li>
<p>A project has already been prepared for you to work in</p>
</li>
<li>
<p>Click on the project <code>team-1-ai</code></p>
</li>
<li>
<p>In your project go on the tab <strong>Workbenches</strong></p>
</li>
<li>
<p>Click on <strong>Create workbench</strong> and enter these values</p>
<div class="ulist">
<ul>
<li>
<p><strong>Name:</strong></p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">s3-browser</code></pre>
</div>
</div>
</li>
<li>
<p><strong>Notebook image</strong></p>
<div class="ulist">
<ul>
<li>
<p>Image Selection: <code>S3 Browser</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Connections</strong></p>
<div class="ulist">
<ul>
<li>
<p>Click on <strong>Attach existing connections</strong></p>
<div class="ulist">
<ul>
<li>
<p>Select <code>workbench-bucket</code> connection</p>
<div class="imageblock">
<div class="content">
<img src="_images/attach-existing-connection.png" alt="attach existing connection">
</div>
</div>
</li>
<li>
<p>Click on <strong>Attach</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Click on <strong>Create Workbench</strong></p>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Wait until the <strong>Status</strong> of the Workbench is changed from "Starting" to "Running", this can take 2-3 minutes.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/workbench-running-s3.png" alt="workbench running s3">
</div>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Click on the Open link, next to the Workbench name link to open the JuypterLab Workbench</p>
</li>
<li>
<p>Accept the disclaimer</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The browser will show you the contents of your bucket.  Except for a folder called <code>backup</code> that contains some backup models, it will look fairly empty before the pipeline finishes.</p>
</div>
<div class="paragraph">
<p>Now is a good time to grab some coffee, or if you are curious read up on the architecture and requirements of the <a href="https://docs.ultralytics.com/models/yolov5/" target="_blank" rel="noopener">Yolov5 model family</a>. There are different sizing versions of the <a href="https://docs.ultralytics.com/models/yolov5/" target="_blank" rel="noopener">Yolov5</a> and compute requirements. In the pipeline start form you could actually change the model version, and while the pipeline is at the model training step, you can see the loss functions in the logs.</p>
</div>
<div class="paragraph">
<p>Once the pipeline has run (Check the run) successfully the final model named latest-version.onnx will be saved in your S3 bucket. Have look in your S3 Browser. You should see a folder models with you models.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Click on <code>models</code> and you see</p>
<div class="imageblock">
<div class="content">
<img src="_images/s3-browser.png" alt="s3 browser">
</div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_model_serving"><a class="anchor" href="#_model_serving"></a>Model Serving</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You now have a trained model for object recognition. To use the model we will deploy it into <strong>OpenShift AI</strong> Model Serving, which will make it available via an API.</p>
</div>
<div class="sect2">
<h3 id="_model_runtime"><a class="anchor" href="#_model_runtime"></a>Model Runtime</h3>
<div class="paragraph">
<p>First we need to configure a model server:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Click on <strong>Data Science Projects</strong> in the main menu on the left and make sure you have selected your <code>team-1-ai</code> again</p>
</li>
<li>
<p>Select the tab <strong>Models</strong></p>
</li>
<li>
<p>Choose <strong>Multi-model serving platform</strong> by clicking <strong>Select multi-model</strong></p>
</li>
<li>
<p>Now deploy a model server by clicking <strong>Add model server</strong></p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_fill_out_the_form"><a class="anchor" href="#_fill_out_the_form"></a>Fill out the form.</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Model server name:</strong></p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">ovms</code></pre>
</div>
</div>
</li>
<li>
<p><strong>Serving runtime</strong>: <code>OpenVINO Model Server</code></p>
</li>
<li>
<p><strong>Accelerator</strong>: <code>None</code></p>
</li>
<li>
<p><strong>Model route</strong></p>
<div class="ulist">
<ul>
<li>
<p>☑︎ Make deployed models available through an external route: <code>Check</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Token authentication</strong></p>
<div class="ulist">
<ul>
<li>
<p>☑︎ Require token authentication : <code>Check</code></p>
</li>
<li>
<p><strong>Service account name</strong> : <code>default-name</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>Click <strong>Add</strong></p>
</li>
</ul>
</div>
<details>
<summary class="title"><strong>Click to reveal the screenshot</strong></summary>
<div class="content">
<div class="imageblock">
<div class="content">
<img src="_images/serving-runtime.png" alt="serving runtime">
</div>
</div>
</div>
</details>
</div>
</div>
<div class="sect2">
<h3 id="_deploy_model"><a class="anchor" href="#_deploy_model"></a>Deploy Model</h3>
<div class="ulist">
<ul>
<li>
<p>Under <strong>Models and model servers</strong> you&#8217;ll see your new model server</p>
</li>
<li>
<p>Click <strong>Deploy model</strong></p>
</li>
<li>
<p>In the form enter</p>
<div class="ulist">
<ul>
<li>
<p>Model deployment name:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">fedora-detection-service</code></pre>
</div>
</div>
</li>
<li>
<p>Model framework (name-version): <code>onnx-1</code></p>
</li>
<li>
<p>Existing data connection: <code>workbench-bucket</code></p>
</li>
<li>
<p>Path:</p>
<div class="listingblock execute">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">models/model-latest.onnx</code></pre>
</div>
</div>
</li>
<li>
<p>Click <strong>Deploy</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Wait for the server to start. It may take a bit before the model server is able to answer requests. If you get an error in the following calls, just wait a few seconds and try again.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_model_testing"><a class="anchor" href="#_model_testing"></a>Model Testing</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now it&#8217;s time to finally test the model. And since we are Data Scientists here, we&#8217;ll run the first tests to see how the model is performing in our JupyterLab Workbench.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Copy the inference endpoint URL that is published through an OpenShift Route (and save it somewhere)</p>
<div class="imageblock">
<div class="content">
<img src="_images/copy-inference-url.png" alt="copy inference url">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/copy-inference-url2.png" alt="copy inference url2">
</div>
</div>
</li>
<li>
<p>Copy the token of the endpoint</p>
<div class="imageblock">
<div class="content">
<img src="_images/copy-token.png" alt="copy token">
</div>
</div>
</li>
<li>
<p>Back in your JupyterLab Workbench in the <code>object-detection-notebooks</code> directory, open the <code>online-scoring.ipynb</code> notebook</p>
</li>
<li>
<p>Look for the variables <code>prediction_url</code> and <code>token</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">prediction_url = 'REPLACE_ME'
token = 'REPLACE_ME'</code></pre>
</div>
</div>
</li>
<li>
<p>Paste the inference endpoint URL and the token you copied before into the placeholders</p>
</li>
<li>
<p>Run the full notebook (the button with the two play icons in the top menu)</p>
<div class="imageblock">
<div class="content">
<img src="_images/run-full-notebook.png" alt="run full notebook">
</div>
</div>
</li>
<li>
<p>Confirm to <strong>Restart the Kernel</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You will see any identified classes with bounding boxes and confidence score at the end of the notebook.</p>
</div>
<div class="paragraph">
<p>You can test your model with different images in the <code>sample-images</code> folder, or even better, you can upload your own images. Take some pictures with your laptop or smartphone of a the fedora on the floor and upload them into the <code>sample_images</code> folder. Make sure you adjust the image name in <code>image_path</code> variable before running the notebook again AND that the format of the images you take is set to square resolution. This can be adjusted in most smartphones today. If you dont use square resolution, the printed bounding boxes may be drawn in the wrong areas of the pictures.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If you see multiple bounding boxes over your fedoras, that means you may need to filter out object detections with a lower score. By default the code filters out anything with a lower confidence score that 0.3. Search for the code <code>conf_thres=0.3</code>. Increase the threshold here by changing the value and rerun your Notebook.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>And that&#8217;s it for the data science part. It is finally time to handoff your amazing AI Fedora Detection service to the dev team. Make a note and use the two values <code>prediction_url</code> and <code>token</code> in your app in the next chapter.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_expected_outcome_of_this_chapter"><a class="anchor" href="#_expected_outcome_of_this_chapter"></a>Expected outcome of this chapter</h2>
<div class="sectionbody">
<div class="paragraph">
<p>After this chapter you should know:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to label images for training an image detection model</p>
</li>
<li>
<p>how to train and test an AI model in OpenShift AI</p>
</li>
<li>
<p>how to make your model available for inferencing using the model server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>If anything is unclear about these takeaways, please talk to your friendly facilitators.</p>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="index.html" class="query-params-link">Lab guide</a></span>
  <span class="next"><a href="control-robot.html" class="query-params-link">1. Control your Robot</a></span>
</nav>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <a class="rhd-logo" href="https://developers.redhat.com" target="_blank"></div>
</footer>
<script src="../../_/js/vendor/clipboard.js"></script>
<script src="../../_/js/site.js"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
